{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "      <th>len</th>\n",
       "      <th>alphaUC</th>\n",
       "      <th>alphaLC</th>\n",
       "      <th>number</th>\n",
       "      <th>symbol</th>\n",
       "      <th>midChar</th>\n",
       "      <th>repChar</th>\n",
       "      <th>uniqueChar</th>\n",
       "      <th>consecAlphaUC</th>\n",
       "      <th>consecAlphaLC</th>\n",
       "      <th>consecNumber</th>\n",
       "      <th>consecSymbol</th>\n",
       "      <th>seqAlpha</th>\n",
       "      <th>seqNumber</th>\n",
       "      <th>seqKeyboard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>csillik</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>huniihuu</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chaipy</td>\n",
       "      <td>0.172331</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>876876b</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miiwhy</td>\n",
       "      <td>0.154795</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   password  strength  len  alphaUC  alphaLC  number  symbol  midChar  \\\n",
       "0   csillik  0.180594    7        0        7       0       0        0   \n",
       "1  huniihuu  0.177778    8        0        8       0       0        0   \n",
       "2    chaipy  0.172331    6        0        6       0       0        0   \n",
       "3   876876b  0.155556    7        0        1       6       0        5   \n",
       "4    miiwhy  0.154795    6        0        6       0       0        0   \n",
       "\n",
       "   repChar  uniqueChar  consecAlphaUC  consecAlphaLC  consecNumber  \\\n",
       "0        2           5              0              1             0   \n",
       "1        4           4              0              2             0   \n",
       "2        0           6              0              0             0   \n",
       "3        3           4              0              0             0   \n",
       "4        1           5              0              1             0   \n",
       "\n",
       "   consecSymbol  seqAlpha  seqNumber  seqKeyboard  \n",
       "0             0         0          0            0  \n",
       "1             0         0          0            0  \n",
       "2             0         0          0            0  \n",
       "3             0         0          1            0  \n",
       "4             0         0          0            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/transform_sample_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    AdaBoostRegressor,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import (\n",
    "    LassoLars,\n",
    "    Ridge,\n",
    "    BayesianRidge,\n",
    "    Lasso,\n",
    "    LinearRegression,\n",
    "    HuberRegressor,\n",
    "    PassiveAggressiveRegressor,\n",
    "    ElasticNet,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(verbose=0, allow_writing_files=False),\n",
    "    \"Light Gradient Boosting Machine\": LGBMRegressor(),\n",
    "    \"Extra Trees Regressor\": ExtraTreesRegressor(),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(),\n",
    "    \"Extreme Gradient Boosting\": XGBRegressor(),\n",
    "    \"Lasso Least Angle Regression\": LassoLars(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Bayesian Ridge\": BayesianRidge(),\n",
    "    \"Least Angle Regression\": LassoLars(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Huber Regressor\": HuberRegressor(max_iter=1000),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
    "    \"Orthogonal Matching Pursuit\": PassiveAggressiveRegressor(),\n",
    "    \"Passive Aggressive Regressor\": PassiveAggressiveRegressor(),\n",
    "    \"Elastic Net\": ElasticNet(),\n",
    "    \"K Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Dummy Regressor\": DummyRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"strength\",'password'], axis=1)\n",
    "y = df[\"strength\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: Gradient Boosting Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0021\tMSE: 0.0000\tRMSE: 0.0030\tR2: 0.9999\tTT: 4.7752\n",
      "Fold: 1\tMAE: 0.0023\tMSE: 0.0000\tRMSE: 0.0048\tR2: 0.9996\tTT: 1.7018\n",
      "Fold: 2\tMAE: 0.0024\tMSE: 0.0000\tRMSE: 0.0041\tR2: 0.9997\tTT: 1.2483\n",
      "Fold: 3\tMAE: 0.0024\tMSE: 0.0000\tRMSE: 0.0033\tR2: 0.9998\tTT: 1.5315\n",
      "Fold: 4\tMAE: 0.0023\tMSE: 0.0000\tRMSE: 0.0032\tR2: 0.9998\tTT: 1.9080\n",
      "Fold: 5\tMAE: 0.0024\tMSE: 0.0000\tRMSE: 0.0036\tR2: 0.9998\tTT: 1.9622\n",
      "Fold: 6\tMAE: 0.0022\tMSE: 0.0000\tRMSE: 0.0042\tR2: 0.9997\tTT: 1.7978\n",
      "Fold: 7\tMAE: 0.0025\tMSE: 0.0000\tRMSE: 0.0040\tR2: 0.9998\tTT: 1.3138\n",
      "Fold: 8\tMAE: 0.0026\tMSE: 0.0000\tRMSE: 0.0041\tR2: 0.9997\tTT: 1.5807\n",
      "Fold: 9\tMAE: 0.0022\tMSE: 0.0000\tRMSE: 0.0031\tR2: 0.9999\tTT: 1.8202\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0021\tMSE: 0.0000\tRMSE: 0.0035\tR2: 0.9998\tTT: 0.0118\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Random Forest Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0015\tR2: 1.0000\tTT: 4.7250\n",
      "Fold: 1\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0044\tR2: 0.9997\tTT: 3.1737\n",
      "Fold: 2\tMAE: 0.0006\tMSE: 0.0000\tRMSE: 0.0042\tR2: 0.9997\tTT: 3.0847\n",
      "Fold: 3\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0021\tR2: 0.9999\tTT: 3.0453\n",
      "Fold: 4\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0021\tR2: 0.9999\tTT: 2.3199\n",
      "Fold: 5\tMAE: 0.0001\tMSE: 0.0000\tRMSE: 0.0012\tR2: 1.0000\tTT: 2.6330\n",
      "Fold: 6\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0026\tR2: 0.9999\tTT: 2.5010\n",
      "Fold: 7\tMAE: 0.0004\tMSE: 0.0000\tRMSE: 0.0058\tR2: 0.9995\tTT: 2.8150\n",
      "Fold: 8\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0025\tR2: 0.9999\tTT: 3.2288\n",
      "Fold: 9\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0011\tR2: 1.0000\tTT: 2.2062\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0036\tR2: 0.9998\tTT: 0.1055\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: CatBoost Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0004\tMSE: 0.0000\tRMSE: 0.0009\tR2: 1.0000\tTT: 40.1303\n",
      "Fold: 1\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0036\tR2: 0.9998\tTT: 2.4236\n",
      "Fold: 2\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0014\tR2: 1.0000\tTT: 2.3082\n",
      "Fold: 3\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0021\tR2: 0.9999\tTT: 2.2820\n",
      "Fold: 4\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0027\tR2: 0.9999\tTT: 2.1446\n",
      "Fold: 5\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0024\tR2: 0.9999\tTT: 2.2492\n",
      "Fold: 6\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0026\tR2: 0.9999\tTT: 2.4841\n",
      "Fold: 7\tMAE: 0.0007\tMSE: 0.0000\tRMSE: 0.0030\tR2: 0.9999\tTT: 2.1788\n",
      "Fold: 8\tMAE: 0.0006\tMSE: 0.0000\tRMSE: 0.0045\tR2: 0.9997\tTT: 2.2714\n",
      "Fold: 9\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0010\tR2: 1.0000\tTT: 2.3702\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0029\tR2: 0.9999\tTT: 0.0396\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Light Gradient Boosting Machine\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0007\tMSE: 0.0000\tRMSE: 0.0024\tR2: 0.9999\tTT: 4.8030\n",
      "Fold: 1\tMAE: 0.0008\tMSE: 0.0000\tRMSE: 0.0054\tR2: 0.9996\tTT: 1.1081\n",
      "Fold: 2\tMAE: 0.0010\tMSE: 0.0000\tRMSE: 0.0043\tR2: 0.9997\tTT: 1.7024\n",
      "Fold: 3\tMAE: 0.0008\tMSE: 0.0000\tRMSE: 0.0026\tR2: 0.9999\tTT: 1.3970\n",
      "Fold: 4\tMAE: 0.0008\tMSE: 0.0000\tRMSE: 0.0023\tR2: 0.9999\tTT: 1.4890\n",
      "Fold: 5\tMAE: 0.0007\tMSE: 0.0000\tRMSE: 0.0025\tR2: 0.9999\tTT: 1.3285\n",
      "Fold: 6\tMAE: 0.0008\tMSE: 0.0000\tRMSE: 0.0037\tR2: 0.9998\tTT: 2.1883\n",
      "Fold: 7\tMAE: 0.0009\tMSE: 0.0000\tRMSE: 0.0052\tR2: 0.9996\tTT: 0.7226\n",
      "Fold: 8\tMAE: 0.0008\tMSE: 0.0000\tRMSE: 0.0025\tR2: 0.9999\tTT: 0.3169\n",
      "Fold: 9\tMAE: 0.0010\tMSE: 0.0000\tRMSE: 0.0032\tR2: 0.9999\tTT: 0.4521\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0009\tMSE: 0.0000\tRMSE: 0.0040\tR2: 0.9998\tTT: 0.0044\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Extra Trees Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0001\tMSE: 0.0000\tRMSE: 0.0008\tR2: 1.0000\tTT: 2.5404\n",
      "Fold: 1\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0039\tR2: 0.9998\tTT: 2.7216\n",
      "Fold: 2\tMAE: 0.0004\tMSE: 0.0000\tRMSE: 0.0024\tR2: 0.9999\tTT: 2.3701\n",
      "Fold: 3\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0009\tR2: 1.0000\tTT: 2.8054\n",
      "Fold: 4\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0015\tR2: 1.0000\tTT: 2.4689\n",
      "Fold: 5\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0016\tR2: 1.0000\tTT: 2.4532\n",
      "Fold: 6\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0027\tR2: 0.9999\tTT: 2.0242\n",
      "Fold: 7\tMAE: 0.0004\tMSE: 0.0000\tRMSE: 0.0038\tR2: 0.9998\tTT: 2.4215\n",
      "Fold: 8\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0023\tR2: 0.9999\tTT: 2.4992\n",
      "Fold: 9\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0017\tR2: 1.0000\tTT: 2.1641\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0020\tR2: 0.9999\tTT: 0.1229\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: AdaBoost Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0209\tMSE: 0.0006\tRMSE: 0.0254\tR2: 0.9901\tTT: 1.9618\n",
      "Fold: 1\tMAE: 0.0179\tMSE: 0.0005\tRMSE: 0.0230\tR2: 0.9920\tTT: 1.6051\n",
      "Fold: 2\tMAE: 0.0192\tMSE: 0.0006\tRMSE: 0.0244\tR2: 0.9909\tTT: 1.5728\n",
      "Fold: 3\tMAE: 0.0193\tMSE: 0.0006\tRMSE: 0.0238\tR2: 0.9914\tTT: 1.2019\n",
      "Fold: 4\tMAE: 0.0184\tMSE: 0.0006\tRMSE: 0.0236\tR2: 0.9908\tTT: 1.2690\n",
      "Fold: 5\tMAE: 0.0186\tMSE: 0.0006\tRMSE: 0.0235\tR2: 0.9915\tTT: 1.0002\n",
      "Fold: 6\tMAE: 0.0171\tMSE: 0.0005\tRMSE: 0.0221\tR2: 0.9929\tTT: 1.5299\n",
      "Fold: 7\tMAE: 0.0168\tMSE: 0.0005\tRMSE: 0.0226\tR2: 0.9926\tTT: 1.5517\n",
      "Fold: 8\tMAE: 0.0192\tMSE: 0.0006\tRMSE: 0.0249\tR2: 0.9906\tTT: 1.5761\n",
      "Fold: 9\tMAE: 0.0177\tMSE: 0.0005\tRMSE: 0.0232\tR2: 0.9921\tTT: 1.2632\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0172\tMSE: 0.0005\tRMSE: 0.0227\tR2: 0.9921\tTT: 0.0604\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Extreme Gradient Boosting\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0006\tR2: 1.0000\tTT: 4.0128\n",
      "Fold: 1\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0032\tR2: 0.9998\tTT: 1.0301\n",
      "Fold: 2\tMAE: 0.0006\tMSE: 0.0000\tRMSE: 0.0038\tR2: 0.9998\tTT: 1.6077\n",
      "Fold: 3\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0018\tR2: 1.0000\tTT: 0.8986\n",
      "Fold: 4\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0013\tR2: 1.0000\tTT: 0.9801\n",
      "Fold: 5\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0006\tR2: 1.0000\tTT: 0.7474\n",
      "Fold: 6\tMAE: 0.0004\tMSE: 0.0000\tRMSE: 0.0027\tR2: 0.9999\tTT: 0.6976\n",
      "Fold: 7\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0054\tR2: 0.9996\tTT: 0.7441\n",
      "Fold: 8\tMAE: 0.0004\tMSE: 0.0000\tRMSE: 0.0018\tR2: 0.9999\tTT: 1.5485\n",
      "Fold: 9\tMAE: 0.0004\tMSE: 0.0000\tRMSE: 0.0010\tR2: 1.0000\tTT: 0.9586\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0028\tR2: 0.9999\tTT: 0.0030\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Lasso Least Angle Regression\n",
      "\n",
      "Train model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tMAE: 0.2262\tMSE: 0.0647\tRMSE: 0.2543\tR2: -0.0002\tTT: 1.0692\n",
      "Fold: 1\tMAE: 0.2289\tMSE: 0.0663\tRMSE: 0.2575\tR2: -0.0005\tTT: 0.0391\n",
      "Fold: 2\tMAE: 0.2262\tMSE: 0.0655\tRMSE: 0.2559\tR2: -0.0000\tTT: 0.0396\n",
      "Fold: 3\tMAE: 0.2234\tMSE: 0.0655\tRMSE: 0.2559\tR2: -0.0008\tTT: 0.0339\n",
      "Fold: 4\tMAE: 0.2152\tMSE: 0.0607\tRMSE: 0.2464\tR2: -0.0022\tTT: 0.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5\tMAE: 0.2221\tMSE: 0.0645\tRMSE: 0.2540\tR2: -0.0021\tTT: 0.0097\n",
      "Fold: 6\tMAE: 0.2335\tMSE: 0.0691\tRMSE: 0.2628\tR2: -0.0020\tTT: 0.0182\n",
      "Fold: 7\tMAE: 0.2329\tMSE: 0.0688\tRMSE: 0.2622\tR2: -0.0003\tTT: 0.0206\n",
      "Fold: 8\tMAE: 0.2278\tMSE: 0.0660\tRMSE: 0.2568\tR2: -0.0005\tTT: 0.0170\n",
      "Fold: 9\tMAE: 0.2300\tMSE: 0.0677\tRMSE: 0.2601\tR2: -0.0010\tTT: 0.0136\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.2252\tMSE: 0.0652\tRMSE: 0.2554\tR2: -0.0001\tTT: 0.0032\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Ridge Regression\n",
      "\n",
      "Train model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tMAE: 0.0327\tMSE: 0.0019\tRMSE: 0.0433\tR2: 0.9710\tTT: 0.2675\n",
      "Fold: 1\tMAE: 0.0329\tMSE: 0.0026\tRMSE: 0.0510\tR2: 0.9607\tTT: 0.0298\n",
      "Fold: 2\tMAE: 0.0342\tMSE: 0.0028\tRMSE: 0.0530\tR2: 0.9571\tTT: 0.0153\n",
      "Fold: 3\tMAE: 0.0331\tMSE: 0.0033\tRMSE: 0.0570\tR2: 0.9503\tTT: 0.0165\n",
      "Fold: 4\tMAE: 0.0340\tMSE: 0.0035\tRMSE: 0.0593\tR2: 0.9419\tTT: 0.0140\n",
      "Fold: 5\tMAE: 0.0327\tMSE: 0.0025\tRMSE: 0.0504\tR2: 0.9605\tTT: 0.0078\n",
      "Fold: 6\tMAE: 0.0339\tMSE: 0.0024\tRMSE: 0.0490\tR2: 0.9652\tTT: 0.0079\n",
      "Fold: 7\tMAE: 0.0332\tMSE: 0.0023\tRMSE: 0.0483\tR2: 0.9661\tTT: 0.0078\n",
      "Fold: 8\tMAE: 0.0334\tMSE: 0.0018\tRMSE: 0.0426\tR2: 0.9725\tTT: 0.0081\n",
      "Fold: 9\tMAE: 0.0312\tMSE: 0.0018\tRMSE: 0.0424\tR2: 0.9734\tTT: 0.0078\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0333\tMSE: 0.0027\tRMSE: 0.0522\tR2: 0.9583\tTT: 0.0037\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Bayesian Ridge\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0327\tMSE: 0.0019\tRMSE: 0.0433\tR2: 0.9710\tTT: 0.2553\n",
      "Fold: 1\tMAE: 0.0329\tMSE: 0.0026\tRMSE: 0.0510\tR2: 0.9607\tTT: 0.0185\n",
      "Fold: 2\tMAE: 0.0342\tMSE: 0.0028\tRMSE: 0.0530\tR2: 0.9571\tTT: 0.0209\n",
      "Fold: 3\tMAE: 0.0331\tMSE: 0.0033\tRMSE: 0.0570\tR2: 0.9503\tTT: 0.0217\n",
      "Fold: 4\tMAE: 0.0340\tMSE: 0.0035\tRMSE: 0.0593\tR2: 0.9419\tTT: 0.0217\n",
      "Fold: 5\tMAE: 0.0328\tMSE: 0.0025\tRMSE: 0.0505\tR2: 0.9604\tTT: 0.0198\n",
      "Fold: 6\tMAE: 0.0339\tMSE: 0.0024\tRMSE: 0.0490\tR2: 0.9652\tTT: 0.0224\n",
      "Fold: 7\tMAE: 0.0332\tMSE: 0.0023\tRMSE: 0.0482\tR2: 0.9662\tTT: 0.0175\n",
      "Fold: 8\tMAE: 0.0334\tMSE: 0.0018\tRMSE: 0.0426\tR2: 0.9725\tTT: 0.0262\n",
      "Fold: 9\tMAE: 0.0312\tMSE: 0.0018\tRMSE: 0.0424\tR2: 0.9734\tTT: 0.0221\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0333\tMSE: 0.0027\tRMSE: 0.0522\tR2: 0.9583\tTT: 0.0032\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Least Angle Regression\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.2262\tMSE: 0.0647\tRMSE: 0.2543\tR2: -0.0002\tTT: 0.0144\n",
      "Fold: 1\tMAE: 0.2289\tMSE: 0.0663\tRMSE: 0.2575\tR2: -0.0005\tTT: 0.0129\n",
      "Fold: 2\tMAE: 0.2262\tMSE: 0.0655\tRMSE: 0.2559\tR2: -0.0000\tTT: 0.0156\n",
      "Fold: 3\tMAE: 0.2234\tMSE: 0.0655\tRMSE: 0.2559\tR2: -0.0008\tTT: 0.0135\n",
      "Fold: 4\tMAE: 0.2152\tMSE: 0.0607\tRMSE: 0.2464\tR2: -0.0022\tTT: 0.0113\n",
      "Fold: 5\tMAE: 0.2221\tMSE: 0.0645\tRMSE: 0.2540\tR2: -0.0021\tTT: 0.0134\n",
      "Fold: 6\tMAE: 0.2335\tMSE: 0.0691\tRMSE: 0.2628\tR2: -0.0020\tTT: 0.0126\n",
      "Fold: 7\tMAE: 0.2329\tMSE: 0.0688\tRMSE: 0.2622\tR2: -0.0003\tTT: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/mnt/d/Code/Python/AI/Passwordometer/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 8\tMAE: 0.2278\tMSE: 0.0660\tRMSE: 0.2568\tR2: -0.0005\tTT: 0.0091\n",
      "Fold: 9\tMAE: 0.2300\tMSE: 0.0677\tRMSE: 0.2601\tR2: -0.0010\tTT: 0.0159\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.2252\tMSE: 0.0652\tRMSE: 0.2554\tR2: -0.0001\tTT: 0.0121\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Lasso Regression\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.1659\tMSE: 0.0338\tRMSE: 0.1838\tR2: 0.4776\tTT: 0.1966\n",
      "Fold: 1\tMAE: 0.1685\tMSE: 0.0347\tRMSE: 0.1864\tR2: 0.4757\tTT: 0.0211\n",
      "Fold: 2\tMAE: 0.1659\tMSE: 0.0341\tRMSE: 0.1847\tR2: 0.4788\tTT: 0.0152\n",
      "Fold: 3\tMAE: 0.1631\tMSE: 0.0338\tRMSE: 0.1839\tR2: 0.4833\tTT: 0.0147\n",
      "Fold: 4\tMAE: 0.1578\tMSE: 0.0314\tRMSE: 0.1773\tR2: 0.4808\tTT: 0.0071\n",
      "Fold: 5\tMAE: 0.1634\tMSE: 0.0338\tRMSE: 0.1837\tR2: 0.4757\tTT: 0.0079\n",
      "Fold: 6\tMAE: 0.1709\tMSE: 0.0359\tRMSE: 0.1896\tR2: 0.4785\tTT: 0.0081\n",
      "Fold: 7\tMAE: 0.1708\tMSE: 0.0361\tRMSE: 0.1901\tR2: 0.4741\tTT: 0.0094\n",
      "Fold: 8\tMAE: 0.1675\tMSE: 0.0347\tRMSE: 0.1863\tR2: 0.4735\tTT: 0.0072\n",
      "Fold: 9\tMAE: 0.1696\tMSE: 0.0356\tRMSE: 0.1887\tR2: 0.4732\tTT: 0.0070\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.1659\tMSE: 0.0343\tRMSE: 0.1853\tR2: 0.4734\tTT: 0.0058\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Linear Regression\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0328\tMSE: 0.0019\tRMSE: 0.0433\tR2: 0.9709\tTT: 0.1934\n",
      "Fold: 1\tMAE: 0.0330\tMSE: 0.0026\tRMSE: 0.0511\tR2: 0.9606\tTT: 0.0351\n",
      "Fold: 2\tMAE: 0.0344\tMSE: 0.0028\tRMSE: 0.0530\tR2: 0.9571\tTT: 0.0359\n",
      "Fold: 3\tMAE: 0.0332\tMSE: 0.0033\tRMSE: 0.0570\tR2: 0.9503\tTT: 0.0185\n",
      "Fold: 4\tMAE: 0.0340\tMSE: 0.0035\tRMSE: 0.0593\tR2: 0.9419\tTT: 0.0261\n",
      "Fold: 5\tMAE: 0.0329\tMSE: 0.0025\tRMSE: 0.0504\tR2: 0.9605\tTT: 0.0235\n",
      "Fold: 6\tMAE: 0.0332\tMSE: 0.0024\tRMSE: 0.0490\tR2: 0.9651\tTT: 0.0226\n",
      "Fold: 7\tMAE: 0.0336\tMSE: 0.0023\tRMSE: 0.0483\tR2: 0.9660\tTT: 0.0216\n",
      "Fold: 8\tMAE: 0.0335\tMSE: 0.0018\tRMSE: 0.0426\tR2: 0.9724\tTT: 0.0224\n",
      "Fold: 9\tMAE: 0.0312\tMSE: 0.0018\tRMSE: 0.0424\tR2: 0.9734\tTT: 0.0169\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0333\tMSE: 0.0027\tRMSE: 0.0522\tR2: 0.9583\tTT: 0.0038\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Huber Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0273\tMSE: 0.0018\tRMSE: 0.0425\tR2: 0.9721\tTT: 0.7399\n",
      "Fold: 1\tMAE: 0.0280\tMSE: 0.0031\tRMSE: 0.0559\tR2: 0.9528\tTT: 0.7375\n",
      "Fold: 2\tMAE: 0.0300\tMSE: 0.0035\tRMSE: 0.0594\tR2: 0.9462\tTT: 0.6135\n",
      "Fold: 3\tMAE: 0.0302\tMSE: 0.0041\tRMSE: 0.0639\tR2: 0.9377\tTT: 0.6664\n",
      "Fold: 4\tMAE: 0.0293\tMSE: 0.0041\tRMSE: 0.0639\tR2: 0.9326\tTT: 0.6756\n",
      "Fold: 5\tMAE: 0.0281\tMSE: 0.0029\tRMSE: 0.0543\tR2: 0.9542\tTT: 0.4927\n",
      "Fold: 6\tMAE: 0.0302\tMSE: 0.0034\tRMSE: 0.0580\tR2: 0.9512\tTT: 0.5918\n",
      "Fold: 7\tMAE: 0.0287\tMSE: 0.0028\tRMSE: 0.0526\tR2: 0.9597\tTT: 0.5350\n",
      "Fold: 8\tMAE: 0.0280\tMSE: 0.0018\tRMSE: 0.0429\tR2: 0.9721\tTT: 0.5747\n",
      "Fold: 9\tMAE: 0.0269\tMSE: 0.0020\tRMSE: 0.0442\tR2: 0.9711\tTT: 0.6966\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0285\tMSE: 0.0032\tRMSE: 0.0566\tR2: 0.9508\tTT: 0.0032\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Decision Tree Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0022\tR2: 0.9999\tTT: 0.0377\n",
      "Fold: 1\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0021\tR2: 0.9999\tTT: 0.0341\n",
      "Fold: 2\tMAE: 0.0005\tMSE: 0.0000\tRMSE: 0.0049\tR2: 0.9996\tTT: 0.0316\n",
      "Fold: 3\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0044\tR2: 0.9997\tTT: 0.0252\n",
      "Fold: 4\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0030\tR2: 0.9999\tTT: 0.0191\n",
      "Fold: 5\tMAE: 0.0001\tMSE: 0.0000\tRMSE: 0.0010\tR2: 1.0000\tTT: 0.0253\n",
      "Fold: 6\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0021\tR2: 0.9999\tTT: 0.0333\n",
      "Fold: 7\tMAE: 0.0004\tMSE: 0.0000\tRMSE: 0.0061\tR2: 0.9995\tTT: 0.0320\n",
      "Fold: 8\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0039\tR2: 0.9998\tTT: 0.0296\n",
      "Fold: 9\tMAE: 0.0002\tMSE: 0.0000\tRMSE: 0.0017\tR2: 1.0000\tTT: 0.0331\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0003\tMSE: 0.0000\tRMSE: 0.0038\tR2: 0.9998\tTT: 0.0088\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Orthogonal Matching Pursuit\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0662\tMSE: 0.0052\tRMSE: 0.0722\tR2: 0.9194\tTT: 0.1450\n",
      "Fold: 1\tMAE: 0.0665\tMSE: 0.0054\tRMSE: 0.0734\tR2: 0.9187\tTT: 0.0285\n",
      "Fold: 2\tMAE: 0.0638\tMSE: 0.0052\tRMSE: 0.0724\tR2: 0.9199\tTT: 0.0285\n",
      "Fold: 3\tMAE: 0.0605\tMSE: 0.0052\tRMSE: 0.0720\tR2: 0.9207\tTT: 0.0240\n",
      "Fold: 4\tMAE: 0.0617\tMSE: 0.0054\tRMSE: 0.0738\tR2: 0.9101\tTT: 0.0153\n",
      "Fold: 5\tMAE: 0.0616\tMSE: 0.0051\tRMSE: 0.0717\tR2: 0.9203\tTT: 0.0168\n",
      "Fold: 6\tMAE: 0.0643\tMSE: 0.0050\tRMSE: 0.0708\tR2: 0.9273\tTT: 0.0208\n",
      "Fold: 7\tMAE: 0.0622\tMSE: 0.0049\tRMSE: 0.0701\tR2: 0.9286\tTT: 0.0176\n",
      "Fold: 8\tMAE: 0.0664\tMSE: 0.0054\tRMSE: 0.0733\tR2: 0.9186\tTT: 0.0188\n",
      "Fold: 9\tMAE: 0.0603\tMSE: 0.0046\tRMSE: 0.0678\tR2: 0.9320\tTT: 0.0170\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0617\tMSE: 0.0052\tRMSE: 0.0720\tR2: 0.9205\tTT: 0.0034\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Passive Aggressive Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0640\tMSE: 0.0049\tRMSE: 0.0701\tR2: 0.9240\tTT: 0.0162\n",
      "Fold: 1\tMAE: 0.0637\tMSE: 0.0052\tRMSE: 0.0721\tR2: 0.9216\tTT: 0.0179\n",
      "Fold: 2\tMAE: 0.0655\tMSE: 0.0054\tRMSE: 0.0735\tR2: 0.9175\tTT: 0.0177\n",
      "Fold: 3\tMAE: 0.0667\tMSE: 0.0058\tRMSE: 0.0761\tR2: 0.9114\tTT: 0.0194\n",
      "Fold: 4\tMAE: 0.0640\tMSE: 0.0056\tRMSE: 0.0747\tR2: 0.9078\tTT: 0.0196\n",
      "Fold: 5\tMAE: 0.0610\tMSE: 0.0051\tRMSE: 0.0711\tR2: 0.9214\tTT: 0.0186\n",
      "Fold: 6\tMAE: 0.0643\tMSE: 0.0050\tRMSE: 0.0706\tR2: 0.9277\tTT: 0.0183\n",
      "Fold: 7\tMAE: 0.0637\tMSE: 0.0051\tRMSE: 0.0712\tR2: 0.9262\tTT: 0.0196\n",
      "Fold: 8\tMAE: 0.0608\tMSE: 0.0046\tRMSE: 0.0677\tR2: 0.9305\tTT: 0.0153\n",
      "Fold: 9\tMAE: 0.0626\tMSE: 0.0048\tRMSE: 0.0692\tR2: 0.9292\tTT: 0.0181\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0634\tMSE: 0.0052\tRMSE: 0.0724\tR2: 0.9196\tTT: 0.0045\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Elastic Net\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.1035\tMSE: 0.0129\tRMSE: 0.1137\tR2: 0.8002\tTT: 0.0122\n",
      "Fold: 1\tMAE: 0.1074\tMSE: 0.0139\tRMSE: 0.1181\tR2: 0.7896\tTT: 0.0119\n",
      "Fold: 2\tMAE: 0.1051\tMSE: 0.0139\tRMSE: 0.1180\tR2: 0.7875\tTT: 0.0105\n",
      "Fold: 3\tMAE: 0.1024\tMSE: 0.0133\tRMSE: 0.1155\tR2: 0.7961\tTT: 0.0083\n",
      "Fold: 4\tMAE: 0.1016\tMSE: 0.0132\tRMSE: 0.1147\tR2: 0.7829\tTT: 0.0073\n",
      "Fold: 5\tMAE: 0.1036\tMSE: 0.0133\tRMSE: 0.1154\tR2: 0.7933\tTT: 0.0069\n",
      "Fold: 6\tMAE: 0.1069\tMSE: 0.0141\tRMSE: 0.1187\tR2: 0.7954\tTT: 0.0070\n",
      "Fold: 7\tMAE: 0.1064\tMSE: 0.0140\tRMSE: 0.1182\tR2: 0.7967\tTT: 0.0087\n",
      "Fold: 8\tMAE: 0.1057\tMSE: 0.0136\tRMSE: 0.1164\tR2: 0.7944\tTT: 0.0095\n",
      "Fold: 9\tMAE: 0.1064\tMSE: 0.0138\tRMSE: 0.1173\tR2: 0.7966\tTT: 0.0126\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.1054\tMSE: 0.0139\tRMSE: 0.1179\tR2: 0.7869\tTT: 0.0049\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: K Neighbors Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.0041\tMSE: 0.0001\tRMSE: 0.0099\tR2: 0.9985\tTT: 0.5092\n",
      "Fold: 1\tMAE: 0.0049\tMSE: 0.0002\tRMSE: 0.0142\tR2: 0.9970\tTT: 0.1337\n",
      "Fold: 2\tMAE: 0.0050\tMSE: 0.0001\tRMSE: 0.0121\tR2: 0.9978\tTT: 0.1528\n",
      "Fold: 3\tMAE: 0.0042\tMSE: 0.0001\tRMSE: 0.0100\tR2: 0.9985\tTT: 0.1550\n",
      "Fold: 4\tMAE: 0.0043\tMSE: 0.0001\tRMSE: 0.0107\tR2: 0.9981\tTT: 0.0804\n",
      "Fold: 5\tMAE: 0.0045\tMSE: 0.0001\tRMSE: 0.0107\tR2: 0.9982\tTT: 0.0570\n",
      "Fold: 6\tMAE: 0.0042\tMSE: 0.0001\tRMSE: 0.0104\tR2: 0.9984\tTT: 0.0677\n",
      "Fold: 7\tMAE: 0.0043\tMSE: 0.0001\tRMSE: 0.0117\tR2: 0.9980\tTT: 0.0659\n",
      "Fold: 8\tMAE: 0.0047\tMSE: 0.0001\tRMSE: 0.0112\tR2: 0.9981\tTT: 0.1395\n",
      "Fold: 9\tMAE: 0.0048\tMSE: 0.0001\tRMSE: 0.0106\tR2: 0.9983\tTT: 0.1001\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.0041\tMSE: 0.0001\tRMSE: 0.0098\tR2: 0.9985\tTT: 0.0955\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model name: Dummy Regressor\n",
      "\n",
      "Train model\n",
      "Fold: 0\tMAE: 0.2262\tMSE: 0.0647\tRMSE: 0.2543\tR2: -0.0002\tTT: 0.0006\n",
      "Fold: 1\tMAE: 0.2289\tMSE: 0.0663\tRMSE: 0.2575\tR2: -0.0005\tTT: 0.0004\n",
      "Fold: 2\tMAE: 0.2262\tMSE: 0.0655\tRMSE: 0.2559\tR2: -0.0000\tTT: 0.0004\n",
      "Fold: 3\tMAE: 0.2234\tMSE: 0.0655\tRMSE: 0.2559\tR2: -0.0008\tTT: 0.0003\n",
      "Fold: 4\tMAE: 0.2152\tMSE: 0.0607\tRMSE: 0.2464\tR2: -0.0022\tTT: 0.0003\n",
      "Fold: 5\tMAE: 0.2221\tMSE: 0.0645\tRMSE: 0.2540\tR2: -0.0021\tTT: 0.0004\n",
      "Fold: 6\tMAE: 0.2335\tMSE: 0.0691\tRMSE: 0.2628\tR2: -0.0020\tTT: 0.0004\n",
      "Fold: 7\tMAE: 0.2329\tMSE: 0.0688\tRMSE: 0.2622\tR2: -0.0003\tTT: 0.0004\n",
      "Fold: 8\tMAE: 0.2278\tMSE: 0.0660\tRMSE: 0.2568\tR2: -0.0005\tTT: 0.0004\n",
      "Fold: 9\tMAE: 0.2300\tMSE: 0.0677\tRMSE: 0.2601\tR2: -0.0010\tTT: 0.0005\n",
      "\n",
      "Test model\n",
      "Fold: -\tMAE: 0.2252\tMSE: 0.0652\tRMSE: 0.2554\tR2: -0.0001\tTT: 0.0001\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mae = []\n",
    "mse = []\n",
    "rmse = []\n",
    "r2 = []\n",
    "tt = []\n",
    "\n",
    "test_mae = []\n",
    "test_mse = []\n",
    "test_rmse = []\n",
    "test_r2 = []\n",
    "test_tt = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    mae_scores = []\n",
    "    mse_scores = []\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "    tt_scores = []\n",
    "    print(f\"Model name: {model_name}\\n\")\n",
    "    print(\"Train model\")\n",
    "\n",
    "    for k, (train_index, val_index) in enumerate(k_fold.split(X_train, y_train)):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        end_time = time.time()\n",
    "\n",
    "        mae_scores.append(mean_absolute_error(y_val_fold, y_pred))\n",
    "        mse_scores.append(mean_squared_error(y_val_fold, y_pred))\n",
    "        rmse_scores.append(\n",
    "            mean_squared_error(y_val_fold, y_pred, squared=False)\n",
    "        )\n",
    "        r2_scores.append(r2_score(y_val_fold, y_pred))\n",
    "        tt_scores.append(round(end_time - start_time, 4))\n",
    "\n",
    "        print(\n",
    "            f\"Fold: {k}\\tMAE: {mae_scores[-1]:.4f}\\tMSE: {mse_scores[-1]:.4f}\\tRMSE: {rmse_scores[-1]:.4f}\\tR2: {r2_scores[-1]:.4f}\\tTT: {tt_scores[-1]:.4f}\"\n",
    "        )\n",
    "\n",
    "    mae.append(np.mean(mae_scores))\n",
    "    mse.append(np.mean(mse_scores))\n",
    "    rmse.append(np.mean(rmse_scores))\n",
    "    r2.append(np.mean(r2_scores))\n",
    "    tt.append(np.mean(tt_scores))\n",
    "\n",
    "    print(\"\\nTest model\")\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "    tt_scores.append(round(end_time - start_time, 4))\n",
    "\n",
    "    print(\n",
    "        f\"Fold: -\\tMAE: {mae_scores[-1]:.4f}\\tMSE: {mse_scores[-1]:.4f}\\tRMSE: {rmse_scores[-1]:.4f}\\tR2: {r2_scores[-1]:.4f}\\tTT: {tt_scores[-1]:.4f}\"\n",
    "    )\n",
    "\n",
    "    test_mae.append(mae_scores[-1])\n",
    "    test_mse.append(mse_scores[-1])\n",
    "    test_rmse.append(rmse_scores[-1])\n",
    "    test_r2.append(r2_scores[-1])\n",
    "    test_tt.append(tt_scores[-1])\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extra Trees Regressor</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>2.44686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>1.32255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost Regressor</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>6.08424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>2.97326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.999816</td>\n",
       "      <td>0.03010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>1.55079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>1.96395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K Neighbors Regressor</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.011127</td>\n",
       "      <td>0.998096</td>\n",
       "      <td>0.14613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.018504</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.023626</td>\n",
       "      <td>0.991480</td>\n",
       "      <td>1.45317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bayesian Ridge</td>\n",
       "      <td>0.033145</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.049634</td>\n",
       "      <td>0.961869</td>\n",
       "      <td>0.04461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.033143</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.049638</td>\n",
       "      <td>0.961864</td>\n",
       "      <td>0.03825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.033178</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.049655</td>\n",
       "      <td>0.961841</td>\n",
       "      <td>0.04160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Huber Regressor</td>\n",
       "      <td>0.028660</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.053759</td>\n",
       "      <td>0.954959</td>\n",
       "      <td>0.63237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Passive Aggressive Regressor</td>\n",
       "      <td>0.063640</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.071640</td>\n",
       "      <td>0.921723</td>\n",
       "      <td>0.01807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Orthogonal Matching Pursuit</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.071738</td>\n",
       "      <td>0.921554</td>\n",
       "      <td>0.03323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.104893</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.116590</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>0.00949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>0.166347</td>\n",
       "      <td>0.034407</td>\n",
       "      <td>0.185457</td>\n",
       "      <td>0.477120</td>\n",
       "      <td>0.02943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Least Angle Regression</td>\n",
       "      <td>0.226618</td>\n",
       "      <td>0.065859</td>\n",
       "      <td>0.256590</td>\n",
       "      <td>-0.000957</td>\n",
       "      <td>0.01332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lasso Least Angle Regression</td>\n",
       "      <td>0.226618</td>\n",
       "      <td>0.065859</td>\n",
       "      <td>0.256590</td>\n",
       "      <td>-0.000957</td>\n",
       "      <td>0.12840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dummy Regressor</td>\n",
       "      <td>0.226618</td>\n",
       "      <td>0.065859</td>\n",
       "      <td>0.256590</td>\n",
       "      <td>-0.000957</td>\n",
       "      <td>0.00041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model       MAE       MSE      RMSE        R2  \\\n",
       "0             Extra Trees Regressor  0.000263  0.000006  0.002164  0.999914   \n",
       "1         Extreme Gradient Boosting  0.000392  0.000007  0.002214  0.999895   \n",
       "2                CatBoost Regressor  0.000503  0.000007  0.002415  0.999894   \n",
       "3           Random Forest Regressor  0.000284  0.000010  0.002744  0.999855   \n",
       "4           Decision Tree Regressor  0.000270  0.000012  0.003137  0.999816   \n",
       "5   Light Gradient Boosting Machine  0.000833  0.000013  0.003390  0.999808   \n",
       "6       Gradient Boosting Regressor  0.002327  0.000014  0.003740  0.999783   \n",
       "7             K Neighbors Regressor  0.004480  0.000125  0.011127  0.998096   \n",
       "8                AdaBoost Regressor  0.018504  0.000559  0.023626  0.991480   \n",
       "9                    Bayesian Ridge  0.033145  0.002494  0.049634  0.961869   \n",
       "10                 Ridge Regression  0.033143  0.002495  0.049638  0.961864   \n",
       "11                Linear Regression  0.033178  0.002496  0.049655  0.961841   \n",
       "12                  Huber Regressor  0.028660  0.002950  0.053759  0.954959   \n",
       "13     Passive Aggressive Regressor  0.063640  0.005138  0.071640  0.921723   \n",
       "14      Orthogonal Matching Pursuit  0.063354  0.005149  0.071738  0.921554   \n",
       "15                      Elastic Net  0.104893  0.013596  0.116590  0.793260   \n",
       "16                 Lasso Regression  0.166347  0.034407  0.185457  0.477120   \n",
       "17           Least Angle Regression  0.226618  0.065859  0.256590 -0.000957   \n",
       "18     Lasso Least Angle Regression  0.226618  0.065859  0.256590 -0.000957   \n",
       "19                  Dummy Regressor  0.226618  0.065859  0.256590 -0.000957   \n",
       "\n",
       "    TT (Sec)  \n",
       "0    2.44686  \n",
       "1    1.32255  \n",
       "2    6.08424  \n",
       "3    2.97326  \n",
       "4    0.03010  \n",
       "5    1.55079  \n",
       "6    1.96395  \n",
       "7    0.14613  \n",
       "8    1.45317  \n",
       "9    0.04461  \n",
       "10   0.03825  \n",
       "11   0.04160  \n",
       "12   0.63237  \n",
       "13   0.01807  \n",
       "14   0.03323  \n",
       "15   0.00949  \n",
       "16   0.02943  \n",
       "17   0.01332  \n",
       "18   0.12840  \n",
       "19   0.00041  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": list(models.keys()),\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"TT (Sec)\": tt,\n",
    "    }\n",
    ")\n",
    "\n",
    "results.sort_values(\"R2\", axis=0, ascending=False).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
